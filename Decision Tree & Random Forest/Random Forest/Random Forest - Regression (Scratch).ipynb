{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Random Forest - Regression (Scratch)**"
      ],
      "metadata": {
        "id": "4iyAzJiK0vH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "uG1RJOrJoxDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AcBMz4mDPvTi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_diabetes, load_iris, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler, PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, explained_variance_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**"
      ],
      "metadata": {
        "id": "txc-dnUTvyY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, feature_index, threshold, left, right):\n",
        "    self.feature_index = feature_index\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right"
      ],
      "metadata": {
        "id": "JZ9K0ax13xW2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeafNodeRegression:\n",
        "  def __init__(self, y):\n",
        "    self.value = np.mean(y)\n",
        "\n",
        "  def predicted_value(self):\n",
        "    return self.value"
      ],
      "metadata": {
        "id": "OOwM29F83xZi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeRegression:\n",
        "  def __init__(self, max_depth=None, min_samples_split=2, criterion=\"mse\"):\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.criterion = criterion\n",
        "    self.tree = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.tree = self._build_tree(X, y)\n",
        "\n",
        "  def _build_tree(self, X, y, depth=0):\n",
        "    num_samples, num_features = X.shape\n",
        "\n",
        "    # Check stopping criteria\n",
        "    if depth >= self.max_depth or num_samples < self.min_samples_split:\n",
        "      return LeafNodeRegression(y)\n",
        "\n",
        "    # Find the best split\n",
        "    best_feature_index, best_threshold, indices_left, indices_right = self._best_split(X, y, num_features)\n",
        "    if best_feature_index is None:\n",
        "      return LeafNodeRegression(y)\n",
        "\n",
        "    # Recursively build left and right subtrees\n",
        "    left_subtree = self._build_tree(X[indices_left], y[indices_left], depth + 1)\n",
        "    right_subtree = self._build_tree(X[indices_right], y[indices_right], depth + 1)\n",
        "\n",
        "    return Node(best_feature_index, best_threshold, left_subtree, right_subtree)\n",
        "\n",
        "  def _best_split(self, X, y, num_features):\n",
        "    best_gain = -1\n",
        "    best_feature_index = None\n",
        "    best_threshold = None\n",
        "    best_indices_left = None\n",
        "    best_indices_right = None\n",
        "\n",
        "    for feature_index in range(num_features):\n",
        "      thresholds = np.unique(X[:, feature_index])\n",
        "      for threshold in thresholds:\n",
        "        indices_left = np.where(X[:, feature_index] <= threshold)[0]\n",
        "        indices_right = np.where(X[:, feature_index] > threshold)[0]\n",
        "\n",
        "        if len(indices_left) > 0 and len(indices_right) > 0:\n",
        "          gain = self._information_gain(y, indices_left, indices_right)\n",
        "          if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_feature_index = feature_index\n",
        "            best_threshold = threshold\n",
        "            best_indices_left = indices_left\n",
        "            best_indices_right = indices_right\n",
        "\n",
        "    return best_feature_index, best_threshold, best_indices_left, best_indices_right\n",
        "\n",
        "  def _information_gain(self, y, left_indices, right_indices):\n",
        "    impurity_before = self._impurity(y)\n",
        "    impurity_left = self._impurity(y[left_indices])\n",
        "    impurity_right = self._impurity(y[right_indices])\n",
        "\n",
        "    weighted_impurity = (len(left_indices) / len(y)) * impurity_left + (len(right_indices) / len(y)) * impurity_right\n",
        "    return impurity_before - weighted_impurity\n",
        "\n",
        "  def _impurity(self, y):\n",
        "    if self.criterion == \"mse\":\n",
        "      return np.mean((y - np.mean(y)) ** 2)\n",
        "    elif self.criterion == \"mae\":\n",
        "      return np.mean(np.abs(y - np.mean(y)))\n",
        "    else:\n",
        "      raise ValueError(f\"Unknown criterion: {self.criterion}\")\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.array([self._traverse_tree(x, self.tree) for x in X])\n",
        "\n",
        "  def _traverse_tree(self, x, tree):\n",
        "    if isinstance(tree, LeafNodeRegression):\n",
        "      return tree.predicted_value()\n",
        "    else:\n",
        "      if x[tree.feature_index] <= tree.threshold:\n",
        "        return self._traverse_tree(x, tree.left)\n",
        "      else:\n",
        "        return self._traverse_tree(x, tree.right)"
      ],
      "metadata": {
        "id": "jN8nJYaO3z4D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForestRegression:\n",
        "  def __init__(self, n_trees=5, max_depth=10, min_samples_split=2, criterion=\"mse\"):\n",
        "    self.n_trees = n_trees\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.criterion = criterion\n",
        "    self.trees = []\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    for _ in range(self.n_trees):\n",
        "      tree = DecisionTreeRegression(max_depth=self.max_depth, min_samples_split=self.min_samples_split, criterion=self.criterion)\n",
        "      # Bootstrap sampling\n",
        "      sample_indices = np.random.choice(len(X), len(X), replace=True)\n",
        "      X_sample = X[sample_indices]\n",
        "      y_sample = y[sample_indices]\n",
        "      tree.fit(X_sample, y_sample)\n",
        "      self.trees.append(tree)\n",
        "\n",
        "  def predict(self, X):\n",
        "    # Average the predictions from all trees\n",
        "    tree_predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "    return np.mean(tree_predictions, axis=0)\n",
        "\n",
        "  def evaluate(self, X, y):\n",
        "    predictions = self.predict(X)\n",
        "    mse = np.mean((y - predictions) ** 2)\n",
        "    r2 = 1 - (np.sum((y - predictions) ** 2) / np.sum((y - np.mean(y)) ** 2))\n",
        "    return mse, r2\n"
      ],
      "metadata": {
        "id": "JfyLT2J82w4o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "kGMmPMSe4GSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Load the diabetes dataset for regression\n",
        "data = load_diabetes()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "WvDSrCt42w7Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iTCwR_Y2w-C",
        "outputId": "5a9a1b26-13e0-4190-dde4-a1ab959c51cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((353, 10), (89, 10), (353,), (89,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the RandomForest regressor\n",
        "forest_regressor = RandomForestRegression(n_trees=5, max_depth=10, min_samples_split=2, criterion=\"mse\")\n",
        "forest_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "C-v6PTh_2xAY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = forest_regressor.predict(X_test)\n",
        "print(y_pred[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ps-_AaR4EuW",
        "outputId": "a3f8dc09-951d-4e69-d3c8-9edc8846ba56"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[153.34444444 186.03333333 135.4        275.525      140.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "mse, r2 = forest_regressor.evaluate(X_test, y_test)\n",
        "print(f\"MSE: {mse:.2f}\")\n",
        "print(f\"R2: {r2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVb0NRD_2xFu",
        "outputId": "aad10a5f-e86e-4054-b8fb-df999a05b90c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 3094.28\n",
            "R2: 0.42\n"
          ]
        }
      ]
    }
  ]
}