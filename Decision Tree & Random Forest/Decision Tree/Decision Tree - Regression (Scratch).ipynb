{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Decision Tree - Regression (Scratch)**"
      ],
      "metadata": {
        "id": "4iyAzJiK0vH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "uG1RJOrJoxDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AcBMz4mDPvTi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_diabetes, load_iris, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler, PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, explained_variance_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**"
      ],
      "metadata": {
        "id": "txc-dnUTvyY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "  def __init__(self, feature=None, threshold=None, left=None, right=None, leaf=False, value=None):\n",
        "    self.feature = feature\n",
        "    self.threshold = threshold\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.leaf = leaf\n",
        "    self.value = value"
      ],
      "metadata": {
        "id": "qn8gdDwgzZE1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeRegressor:\n",
        "  def __init__(self, criterion='mse', max_depth=None, min_samples_split=2):\n",
        "    self.criterion = criterion\n",
        "    self.max_depth = max_depth\n",
        "    self.min_samples_split = min_samples_split\n",
        "    self.tree = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    self.tree = self._build_tree(X, y)\n",
        "\n",
        "  def _build_tree(self, X, y, depth=0):\n",
        "    # Stopping criteria\n",
        "    if len(y) < self.min_samples_split or (self.max_depth and depth >= self.max_depth):\n",
        "        return self._create_leaf_node(y)\n",
        "\n",
        "    # Find the best split\n",
        "    best_feature, best_threshold = self._find_best_split(X, y)\n",
        "    if best_feature is None:\n",
        "        return self._create_leaf_node(y)\n",
        "\n",
        "    # Split the data\n",
        "    left_indices = X[:, best_feature] < best_threshold\n",
        "    right_indices = X[:, best_feature] >= best_threshold\n",
        "\n",
        "    left_child = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "    right_child = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "    return Node(feature=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
        "\n",
        "  def _find_best_split(self, X, y):\n",
        "    best_gain = -np.inf\n",
        "    best_feature = None\n",
        "    best_threshold = None\n",
        "    n_features = X.shape[1]\n",
        "\n",
        "    for feature in range(n_features):\n",
        "        thresholds = np.unique(X[:, feature])\n",
        "        for threshold in thresholds:\n",
        "            gain = self._information_gain(X, y, feature, threshold)\n",
        "            if gain > best_gain:\n",
        "                best_gain = gain\n",
        "                best_feature = feature\n",
        "                best_threshold = threshold\n",
        "\n",
        "    return best_feature, best_threshold\n",
        "\n",
        "  def _information_gain(self, X, y, feature, threshold):\n",
        "    # Calculate the loss before the split\n",
        "    parent_loss = self._loss(y)\n",
        "\n",
        "    # Split the data\n",
        "    left_indices = X[:, feature] < threshold\n",
        "    right_indices = X[:, feature] >= threshold\n",
        "\n",
        "    # Calculate the weighted loss of the children\n",
        "    n = len(y)\n",
        "    n_left = np.sum(left_indices)\n",
        "    n_right = np.sum(right_indices)\n",
        "\n",
        "    if n_left == 0 or n_right == 0:\n",
        "        return 0\n",
        "\n",
        "    child_loss = (n_left / n) * self._loss(y[left_indices]) + (n_right / n) * self._loss(y[right_indices])\n",
        "\n",
        "    # Calculate information gain (parent loss - child loss)\n",
        "    return parent_loss - child_loss\n",
        "\n",
        "  def _loss(self, y):\n",
        "    if self.criterion == 'mse':\n",
        "        return np.mean((y - np.mean(y)) ** 2)\n",
        "    elif self.criterion == 'mae':\n",
        "        return np.mean(np.abs(y - np.mean(y)))\n",
        "\n",
        "  def _create_leaf_node(self, y):\n",
        "    # Leaf node returns the mean value for regression\n",
        "    return Node(leaf=True, value=np.mean(y))\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.array([self._predict_sample(sample, self.tree) for sample in X])\n",
        "\n",
        "  def _predict_sample(self, sample, tree):\n",
        "    if tree.leaf:\n",
        "        return tree.value\n",
        "\n",
        "    if sample[tree.feature] < tree.threshold:\n",
        "        return self._predict_sample(sample, tree.left)\n",
        "    else:\n",
        "        return self._predict_sample(sample, tree.right)\n",
        "\n",
        "  def print_tree(self, tree=None, indent=\"  \"):\n",
        "    \"\"\"Prints the structure of the decision tree\"\"\"\n",
        "    if tree is None:\n",
        "        tree = self.tree\n",
        "    if tree.leaf:\n",
        "        print(f\"{indent}Leaf: Value {tree.value:.2f}\")\n",
        "    else:\n",
        "        print(f\"{indent}Feature {tree.feature} <= {tree.threshold}\")\n",
        "        print(f\"{indent}Left:\")\n",
        "        self.print_tree(tree.left, indent + \"  \")\n",
        "        print(f\"{indent}Right:\")\n",
        "        self.print_tree(tree.right, indent + \"  \")\n"
      ],
      "metadata": {
        "id": "jsmGvhY6y-Pt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "elj1Nq_60hpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset for regression\n",
        "diabetes = load_diabetes()\n",
        "X, y = diabetes.data, diabetes.target"
      ],
      "metadata": {
        "id": "J4J2lVbBzfPF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2X7XS8Jzf4q",
        "outputId": "8efdcb6f-5811-45a6-8cd8-587708f39678"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((353, 10), (89, 10), (353,), (89,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the custom decision tree regressor\n",
        "tree_regressor = DecisionTreeRegressor(criterion='mse', max_depth=5, min_samples_split=3)\n",
        "tree_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "yeLFeictzf8P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the tree structure\n",
        "tree_regressor.print_tree()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRYFhB7zzmnq",
        "outputId": "4720711d-ce77-4cd4-bb37-f405e1ed227b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature 2 <= 0.005649978676881689\n",
            "  Left:\n",
            "    Feature 8 <= 0.007027139682585861\n",
            "    Left:\n",
            "      Feature 8 <= -0.042570854118219384\n",
            "      Left:\n",
            "        Feature 4 <= -0.038719686991641515\n",
            "        Left:\n",
            "          Feature 4 <= -0.04559945128264711\n",
            "          Left:\n",
            "            Leaf: Value 84.08\n",
            "          Right:\n",
            "            Leaf: Value 158.75\n",
            "        Right:\n",
            "          Feature 0 <= 0.04170844488444244\n",
            "          Left:\n",
            "            Leaf: Value 55.40\n",
            "          Right:\n",
            "            Leaf: Value 79.83\n",
            "      Right:\n",
            "        Feature 6 <= 0.026550272625626974\n",
            "        Left:\n",
            "          Feature 4 <= -0.051103262715451604\n",
            "          Left:\n",
            "            Leaf: Value 157.67\n",
            "          Right:\n",
            "            Leaf: Value 113.60\n",
            "        Right:\n",
            "          Feature 0 <= 0.005383060374248237\n",
            "          Left:\n",
            "            Leaf: Value 75.60\n",
            "          Right:\n",
            "            Leaf: Value 105.84\n",
            "    Right:\n",
            "      Feature 7 <= 0.10811110062954676\n",
            "      Left:\n",
            "        Feature 0 <= 0.001750521923228816\n",
            "        Left:\n",
            "          Feature 0 <= -0.052737554842062495\n",
            "          Left:\n",
            "            Leaf: Value 195.00\n",
            "          Right:\n",
            "            Leaf: Value 124.78\n",
            "        Right:\n",
            "          Feature 4 <= -0.008448724111216851\n",
            "          Left:\n",
            "            Leaf: Value 240.43\n",
            "          Right:\n",
            "            Leaf: Value 157.81\n",
            "      Right:\n",
            "        Feature 0 <= -0.030942324135945967\n",
            "        Left:\n",
            "          Leaf: Value 292.00\n",
            "        Right:\n",
            "          Leaf: Value 238.50\n",
            "  Right:\n",
            "    Feature 2 <= 0.0735521393313721\n",
            "    Left:\n",
            "      Feature 9 <= 0.036201264733044136\n",
            "      Left:\n",
            "        Feature 8 <= -0.03452177701362266\n",
            "        Left:\n",
            "          Feature 6 <= -0.01394774321932938\n",
            "          Left:\n",
            "            Leaf: Value 163.33\n",
            "          Right:\n",
            "            Leaf: Value 106.43\n",
            "        Right:\n",
            "          Feature 3 <= 0.052858044296680055\n",
            "          Left:\n",
            "            Leaf: Value 171.67\n",
            "          Right:\n",
            "            Leaf: Value 220.65\n",
            "      Right:\n",
            "        Feature 8 <= 0.0020044426444966374\n",
            "        Left:\n",
            "          Feature 0 <= 0.016280675727306498\n",
            "          Left:\n",
            "            Leaf: Value 85.00\n",
            "          Right:\n",
            "            Leaf: Value 143.00\n",
            "        Right:\n",
            "          Feature 5 <= 0.19878798965729408\n",
            "          Left:\n",
            "            Leaf: Value 246.62\n",
            "          Right:\n",
            "            Leaf: Value 84.00\n",
            "    Right:\n",
            "      Feature 5 <= 0.023424851055154544\n",
            "      Left:\n",
            "        Feature 7 <= 0.03430885887772673\n",
            "        Left:\n",
            "          Feature 1 <= 0.05068011873981862\n",
            "          Left:\n",
            "            Leaf: Value 264.17\n",
            "          Right:\n",
            "            Leaf: Value 295.00\n",
            "        Right:\n",
            "          Feature 3 <= 0.0666294482000771\n",
            "          Left:\n",
            "            Leaf: Value 339.67\n",
            "          Right:\n",
            "            Leaf: Value 290.75\n",
            "      Right:\n",
            "        Feature 3 <= -0.019441826196154435\n",
            "        Left:\n",
            "          Leaf: Value 292.50\n",
            "        Right:\n",
            "          Feature 2 <= 0.09834181703063047\n",
            "          Left:\n",
            "            Leaf: Value 169.33\n",
            "          Right:\n",
            "            Leaf: Value 237.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = tree_regressor.predict(X_test)\n",
        "print(y_pred[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcy9abbXzo2u",
        "outputId": "4a4d868e-75ec-4b5e-ff71-f88b2e9bfdf7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[157.80769231 171.67241379 157.80769231 246.62068966 113.59615385]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the regression performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MSE: {mse:.2f}')\n",
        "print(f'MAE: {mae:.2f}')\n",
        "print(f'R2: {r2:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfhxrclkzsc2",
        "outputId": "9444fd36-0c24-4e22-8053-8745f151db6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 3754.26\n",
            "MAE: 47.72\n",
            "R2: 0.29\n"
          ]
        }
      ]
    }
  ]
}