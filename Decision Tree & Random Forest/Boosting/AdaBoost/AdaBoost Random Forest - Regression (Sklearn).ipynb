{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**AdaBoost Random Forest - Regression (Sklearn)**"
      ],
      "metadata": {
        "id": "4iyAzJiK0vH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "uG1RJOrJoxDi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AcBMz4mDPvTi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_diabetes, load_iris, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler, PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, RidgeClassifier, Ridge, Lasso, ElasticNet\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
        "from sklearn.ensemble import VotingClassifier, VotingRegressor\n",
        "from sklearn.ensemble import StackingClassifier, StackingRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
        "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, explained_variance_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Uisng Sklearn**"
      ],
      "metadata": {
        "id": "0n4DS8KO415I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load the diabetes dataset for regression\n",
        "data = load_diabetes()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest Regressor\n",
        "random_forest = RandomForestRegressor(n_estimators=5, max_depth=10, random_state=42)\n",
        "\n",
        "# Create an AdaBoost Regressor with Random Forest as the base estimator\n",
        "adaboost = AdaBoostRegressor(estimator=random_forest, n_estimators=3, learning_rate=1.0, random_state=42)\n",
        "\n",
        "# Fit the AdaBoost model\n",
        "adaboost.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = adaboost.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "\n",
        "# Summary of the number of trees and forests\n",
        "print(f\"Total number of Random Forests used: {3}\")\n",
        "print(f\"Each Random Forest contains {5} trees.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viGi0fRO8YBJ",
        "outputId": "d2224850-e29b-46a9-efe0-8a661d0939d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 3199.36\n",
            "Total number of Random Forests used: 3\n",
            "Each Random Forest contains 5 trees.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using AdaBoost Class**"
      ],
      "metadata": {
        "id": "IPUHKK9e8cqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "class AdaBoost:\n",
        "    def __init__(self, n_estimators=5, learning_rate=1, n_trees_per_forest=5):\n",
        "        self.n_estimators = n_estimators      # Number of forests (weak learners)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_trees_per_forest = n_trees_per_forest  # Trees per forest\n",
        "        self.models = []\n",
        "        self.alphas = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples = len(y)\n",
        "        # Initialize weights\n",
        "        weights = np.ones(n_samples) / n_samples\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            # Create a random forest regressor as the weak learner\n",
        "            model = RandomForestRegressor(n_estimators=self.n_trees_per_forest, max_depth=3, random_state=42)\n",
        "            model.fit(X, y, sample_weight=weights)\n",
        "            y_pred = model.predict(X)\n",
        "\n",
        "            # Compute the error\n",
        "            error = np.mean((y_pred - y) ** 2)\n",
        "            if error >= 1:  # If the error is too high, skip this estimator\n",
        "                continue\n",
        "\n",
        "            alpha = self.learning_rate * 0.5 * np.log((1 - error) / (error + 1e-10))  # Avoid division by zero\n",
        "\n",
        "            # Update weights\n",
        "            weights *= np.exp(-alpha * (y_pred - y) ** 2)  # Adjust this for regression\n",
        "            weights /= np.sum(weights)  # Normalize weights\n",
        "\n",
        "            self.models.append(model)\n",
        "            self.alphas.append(alpha)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Compute the weighted sum of the predictions from all models\n",
        "        final_prediction = np.zeros(X.shape[0])  # Initialize with zeros\n",
        "        for alpha, model in zip(self.alphas, self.models):\n",
        "            final_prediction += alpha * model.predict(X)\n",
        "        return final_prediction\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        predictions = self.predict(X)\n",
        "        mse = np.mean((y - predictions) ** 2)\n",
        "        return mse\n",
        "\n",
        "    def report_forest_info(self):\n",
        "        # Reporting the number of forests (weak learners) and trees per forest\n",
        "        print(f\"Number of forests (weak learners): {len(self.models)}\")\n",
        "        if len(self.models) > 0:\n",
        "            print(f\"Number of trees per forest: {self.n_trees_per_forest}\")\n",
        "\n",
        "# Load the diabetes dataset for regression\n",
        "data = load_diabetes()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the AdaBoost regressor with Random Forest as the base learner\n",
        "adaboost_regressor = AdaBoost(n_estimators=3, learning_rate=1, n_trees_per_forest=5)  # 3 forests with 5 trees each\n",
        "adaboost_regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = adaboost_regressor.predict(X_test)\n",
        "print(\"First 5 Predictions:\", y_pred[:5])\n",
        "\n",
        "# Evaluate\n",
        "mse = adaboost_regressor.evaluate(X_test, y_test)\n",
        "print(f\"MSE: {mse:.2f}\")\n",
        "\n",
        "# Report the number of forests and trees per forest\n",
        "adaboost_regressor.report_forest_info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcpqxckS9GTd",
        "outputId": "951f976a-51fa-4eab-9da9-ae4e383d4c9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 Predictions: [0. 0. 0. 0. 0.]\n",
            "MSE: 26548.58\n",
            "Number of forests (weak learners): 0\n"
          ]
        }
      ]
    }
  ]
}