{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**XGBoost Random Forest - Classification (Sklearn)**"
      ],
      "metadata": {
        "id": "4iyAzJiK0vH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "uG1RJOrJoxDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.datasets import load_diabetes, load_iris, fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler, PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, explained_variance_score\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBRegressor, XGBClassifier"
      ],
      "metadata": {
        "id": "WBhBkbuTkfZV"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code**"
      ],
      "metadata": {
        "id": "nOofeYvYAa3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForestWithXGBoost:\n",
        "    def __init__(self, n_forests=1, n_trees=5, max_depth=10, min_samples_split=2, xgboost_trees=2):\n",
        "        self.n_forests = n_forests  # Number of random forests\n",
        "        self.n_trees = n_trees  # Number of trees in each random forest\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.xgboost_trees = xgboost_trees  # Number of XGBoost trees\n",
        "        self.forests = []  # Store the forests\n",
        "        self.rf_model = None  # Random Forest model\n",
        "        self.xgb_model = None  # XGBoost model\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # Train Random Forest Classifier\n",
        "        self.rf_model = RandomForestClassifier(n_estimators=self.n_trees, max_depth=self.max_depth,\n",
        "                                               min_samples_split=self.min_samples_split, random_state=42)\n",
        "        self.rf_model.fit(X, y)\n",
        "\n",
        "        # Print Random Forest structure\n",
        "        print(\"\\nRandom Forest trained with the following parameters:\")\n",
        "        print(f\"n_trees: {self.n_trees}, max_depth: {self.max_depth}, min_samples_split: {self.min_samples_split}\")\n",
        "\n",
        "        # Train XGBoost model\n",
        "        self.xgb_model = xgb.XGBClassifier(n_estimators=self.xgboost_trees, max_depth=self.max_depth,\n",
        "                                            objective='multi:softmax', eval_metric='mlogloss', random_state=42)\n",
        "        self.xgb_model.fit(X, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Get predictions from Random Forest\n",
        "        rf_preds = self.rf_model.predict(X)\n",
        "        print(f\"Random Forest predictions: {rf_preds}\")\n",
        "\n",
        "        # Get predictions from XGBoost\n",
        "        xgb_preds = self.xgb_model.predict(X)\n",
        "        print(f\"XGBoost predictions: {xgb_preds}\")\n",
        "\n",
        "        return rf_preds, xgb_preds\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        rf_preds, xgb_preds = self.predict(X)\n",
        "\n",
        "        # Calculate the classification report and confusion matrix for Random Forest\n",
        "        print(\"\\nClassification Report for Random Forest:\")\n",
        "        print(classification_report(y, rf_preds))\n",
        "        print(\"Confusion Matrix for Random Forest:\")\n",
        "        print(confusion_matrix(y, rf_preds))\n",
        "\n",
        "        # Calculate the classification report and confusion matrix for XGBoost\n",
        "        print(\"\\nClassification Report for XGBoost:\")\n",
        "        print(classification_report(y, xgb_preds))\n",
        "        print(\"Confusion Matrix for XGBoost:\")\n",
        "        print(confusion_matrix(y, xgb_preds))"
      ],
      "metadata": {
        "id": "wTtBWR9Gi6O9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target"
      ],
      "metadata": {
        "id": "Nv7o4ePmjci4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "tZ-fNDCcjclm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train RandomForestWithXGBoost\n",
        "rf_xgb = RandomForestWithXGBoost(n_forests=1, n_trees=5, xgboost_trees=2)\n",
        "rf_xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRqnLQkFjcol",
        "outputId": "f8c9e0aa-a900-4129-b114-6a0bc142463a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest trained with the following parameters:\n",
            "n_trees: 5, max_depth: 10, min_samples_split: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = rf_xgb.predict(X_test)\n",
        "print(y_pred[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzZPn1jqjcrC",
        "outputId": "27ac4afc-8e0a-4640-8cf5-37ba9ccfee40"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 1 0 2 2 2 2 2 0 0]\n",
            "XGBoost predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "(array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 1,\n",
            "       0, 2, 2, 2, 2, 2, 0, 0]), array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
            "       0, 2, 2, 2, 2, 2, 0, 0], dtype=int32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "rf_xgb.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xru2_YRjiJF",
        "outputId": "558cb675-e109-4995-8c43-3f7142bc34c9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 1 0 2 2 2 2 2 0 0]\n",
            "XGBoost predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
            "\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       0.90      1.00      0.95         9\n",
            "           2       1.00      0.91      0.95        11\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "Confusion Matrix for Random Forest:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  1 10]]\n",
            "\n",
            "Classification Report for XGBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n",
            "Confusion Matrix for XGBoost:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n"
          ]
        }
      ]
    }
  ]
}